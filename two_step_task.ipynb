{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Step Task \n",
    " - This notebook simulate the two step task of a agent, store all the Data of the simulation and plot the Stay Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data_frame(df): \n",
    "    # this funcation add to the data frame 3 columns:\n",
    "    # 1 - prev_reward : if the last trail was rewarded\n",
    "    # 2 - transation_prev : if the last transation was common or rare\n",
    "    # 3 - stay probs \n",
    "    \n",
    "    df['prev_reward'] = df['reward'].shift(1,fill_value=0)\n",
    "    df['transation_prev'] = df['transation_type'].shift(1,fill_value=0)\n",
    "    df['stay'] = df['action_statge_1'].shift(1) == df['action_statge_1']\n",
    "\n",
    "def calc_stay_probs(df): \n",
    "    # this funcation retuen a new df of stay prob according to every \n",
    "    # combination of reward/transation 4 option\n",
    "    \n",
    "    return df.groupby(['prev_reward', 'transation_prev'])['stay'].mean().reset_index()\n",
    "    \n",
    "def plot_stay_probs(list_of_stay):\n",
    "    # this funcation plots the stay probs given a list of the stay probs\n",
    "    # each element of the list represents combination of transation/reward\n",
    "    # list_of_stay[0] -> rare/unrewarded | list_of_stay [1] -> common/unrewarded\n",
    "    # list_of_stay[2] -> rare/rewarded | list_of_stay [3] -> common/rewarded\n",
    "    \n",
    "    x_labels = ['Rewarded' ,'Unrewarded']\n",
    "        \n",
    "    common = [list_of_stay[3],list_of_stay[1]]\n",
    "    rare = [list_of_stay[2],list_of_stay[0]]\n",
    "    \n",
    "    # the width of the bars\n",
    "    widthB = 0.35  \n",
    "    r1 = np.arange(len(x_labels))\n",
    "    r2 = [i + widthB for i in r1]\n",
    "    \n",
    "    fig , ax = plt.subplots()\n",
    "\n",
    "    ax.bar(r1,common, color='blue', width=widthB, edgecolor='white', label='Common')\n",
    "    ax.bar(r2, rare, color='red', width=widthB, edgecolor='white', label='Rare')\n",
    "\n",
    "    ax.set_ylabel('Stay Probability',size=12)\n",
    "    ax.set_title('PLOT',size=14)\n",
    "    ax.set_xticks([((2*r + widthB)/2) for r in range(len(x_labels))])\n",
    "    ax.set_xticklabels(x_labels,size=12)\n",
    "    ax.set_ylim((0, 1))  \n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return ax\n",
    "    \n",
    "def calc_main_effect(list_of_stay):\n",
    "     # this funcation retuen the main effect of stay prob\n",
    "    return ((list_of_stay[3] + list_of_stay[2])/2) - ((list_of_stay[1] +list_of_stay[0])/2)\n",
    "\n",
    "def calc_interaction_effect(list_of_stay):\n",
    "    # this funcation retuen the interaction effect of stay prob\n",
    "    return (list_of_stay[3] - list_of_stay[2]) - (list_of_stay[1] - list_of_stay[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataOfSim():\n",
    "    \n",
    "    # this class stores all the data of one simulation\n",
    "    # storing the following: action_1, stage_2_state, transation_type, action_2, reward\n",
    "    def __init__ (self , num_of_trails):\n",
    "        self.action_1_list = np.zeros(num_of_trails)\n",
    "        self.stage_2_state = np.zeros(num_of_trails)\n",
    "        self.transation_list = ['' for i in range(num_of_trails)]\n",
    "        self.action_2_list = np.zeros(num_of_trails)\n",
    "        self.reward_list = np.zeros(num_of_trails) \n",
    "    \n",
    "    def createDic(self):\n",
    "        dic = {\n",
    "                'action_statge_1' : self.action_1_list,\n",
    "                'transation_type' : self.transation_list,\n",
    "                'action_stage_2' : self.action_2_list, \n",
    "                'state_of_stage_2' : self.stage_2_state,\n",
    "                'reward' : self.reward_list\n",
    "        }\n",
    "\n",
    "        return dic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of all parameters\n",
    "\n",
    "# set num of trails\n",
    "num_of_trails = 1000\n",
    "\n",
    "# set num of action \n",
    "action_space = 2\n",
    "\n",
    "# set num of states \n",
    "state_space = 2\n",
    "\n",
    "# set num of stages \n",
    "stages_space = 2\n",
    "\n",
    "# q_values of model free\n",
    "q_mf = np.zeros(shape = (action_space ,state_space, stages_space))\n",
    "\n",
    "# q_values of model based\n",
    "q_mb = np.zeros(action_space)\n",
    "\n",
    "# the weighted sum of model-based and model-free values\n",
    "q_net = np.zeros(2)\n",
    "\n",
    "# set learning rate - α  \n",
    "alpha_1 = 0.5\n",
    "\n",
    "# set discounting factor - γ \n",
    "gamma = 1\n",
    "\n",
    "# set beta temperature - β (for sowftMax)\n",
    "beta = 2\n",
    "\n",
    "# weighting parameter \n",
    "# w = 1 -> MB ; w = 0 -> MF\n",
    "w = 0\n",
    "\n",
    "# state transition structure \n",
    "transition_prob = np.array(\n",
    "                            [[.7,.3],\n",
    "                            [.3,.7]]\n",
    ")\n",
    "\n",
    "\n",
    "expected_reward = np.array(\n",
    "                            [[.8,.5],\n",
    "                            [.5,.8]]\n",
    ")\n",
    "\n",
    "# store data from each trail \n",
    "data = DataOfSim(num_of_trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility funcation used for the q-learning\n",
    "\n",
    "def sowftmax(beta, q):\n",
    "    return (np.exp(q * beta)) / sum(np.exp(q * beta))\n",
    "\n",
    "def prediction_error(a , b): return a-b\n",
    "\n",
    "def update_q_table(q_table, reward, alpha, gamma = 1):\n",
    "    q_table[action] = q_table[action] + gamma * \\\n",
    "                                                (alpha * (prediction_error(reward,q_table[action])))\n",
    "def calculate_q_net(w, q_mb, q_mf):\n",
    "    return (w * q_mb) + ((1-w) * q_mf)\n",
    "\n",
    "def configuration_parameters():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 1 to print step by step trail \n",
    "PRINT_EACH_TRAIL = 0\n",
    "\n",
    "for t in range(num_of_trails):\n",
    "    # this funcation simalate an agent playing the two step task num_of_trails times \n",
    "    # if PRINT_EACH_TRAIL is set to 1 this funcation will output evrey trail \n",
    "\n",
    "    if PRINT_EACH_TRAIL: print(\"----- Trail = {} -----\".format(t))\n",
    "\n",
    "    # Q_model-based values of the first level actions (Bellman’s equation)\n",
    "    q_mb[0] = (transition_prob[0,0]*np.max(q_mf[:,0,1])) + (transition_prob[0,1]*np.max(q_mf[:,1,1]))\n",
    "    q_mb[1] = transition_prob[1,0] * np.max(q_mf[:,0,1]) + transition_prob[1,1] * np.max(q_mf[:,1,1])\n",
    "    if PRINT_EACH_TRAIL: print(\"Q_MB = {}\".format(q_mb))\n",
    "\n",
    "    # net action values at the first stage as the weighted sum of model-based and model-free values\n",
    "    q_net[0] = calculate_q_net(w,q_mb[0],q_mf[0,0,0])\n",
    "    q_net[1] = calculate_q_net(w,q_mb[1],q_mf[1,0,0])\n",
    "\n",
    "    # calc prob with sowftMax for first stage\n",
    "    prob = sowftmax(beta,q_net)[0]\n",
    "    if PRINT_EACH_TRAIL: print(\"Prob 1 = {}\".format(prob))\n",
    "\n",
    "    # choose action_1 according to prob for first stage\n",
    "    action_1 = np.random.choice([0,1] , p = [prob,1-prob])\n",
    "    data.action_1_list[t] = action_1\n",
    "    if PRINT_EACH_TRAIL: print(\"Action 1 = {}\".format(action_1))\n",
    "\n",
    "    # transation to second stage \n",
    "    state = np.random.choice([0,1], p = [transition_prob[action_1,0], 1 - transition_prob[action_1,0]])\n",
    "    transation = 1 if action_1 == state else 0\n",
    "    data.stage_2_state[t] = state\n",
    "    data.transation_list[t] = 1 if transation == 1 else 0\n",
    "    if PRINT_EACH_TRAIL: print(\"Transation to State = {}\".format(state))\n",
    "    if PRINT_EACH_TRAIL: print(\"Transation type = {}\".format('Common' if transation == 1 else 'Rare'))\n",
    "\n",
    "    # calc prob with sowftMax for second stage\n",
    "    prob = sowftmax(beta,q_mf[:,state,1])[0]\n",
    "    if PRINT_EACH_TRAIL: print(\"Prob 2 = {}\".format(prob))\n",
    "\n",
    "    # choose action_2 according to prob for second stage\n",
    "    action_2 = np.random.choice([0,1] ,p = [prob, 1 - prob])\n",
    "    data.action_2_list[t] = action_2\n",
    "    if PRINT_EACH_TRAIL: print(\"Action 2 = {}\".format(action_1))\n",
    "\n",
    "    # cheek if the trail is rewarded\n",
    "    reward = np.random.choice([0,1] , p = [1-expected_reward[state,action_2], expected_reward[state,action_2]])\n",
    "    data.reward_list[t] = reward\n",
    "    if PRINT_EACH_TRAIL: print(\"Reward = {}\".format('YES!' if reward == 1 else 'NO'))\n",
    "\n",
    "    # calculate prediction error\n",
    "    p_e_1 = prediction_error(q_mf[action_2,state,1],q_mf[action_1,0,0])\n",
    "    p_e_2 = prediction_error(reward,q_mf[action_2,state,1])\n",
    "    if PRINT_EACH_TRAIL: print(\"Prediction Error first = {}\".format(p_e_1))\n",
    "    if PRINT_EACH_TRAIL: print(\"Prediction Error second = {}\".format(p_e_2))\n",
    "\n",
    "    # update q_mf according to q_learning formula\n",
    "    q_mf[action_1,0,0] = q_mf[action_1,0,0] + alpha_1 * p_e_1 + gamma * (alpha_1 * p_e_2)\n",
    "    q_mf[action_2,state,1] = q_mf[action_2,state,1] + alpha_1 * p_e_2\n",
    "\n",
    "    if PRINT_EACH_TRAIL: print(\"Q_MF = {}\".format(q_mf))\n",
    "    if PRINT_EACH_TRAIL : input('PRESS ENTER FOR NEXT TRAIL')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data.createDic())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avarge rewared is = 0.697\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_statge_1</th>\n",
       "      <th>transation_type</th>\n",
       "      <th>action_stage_2</th>\n",
       "      <th>state_of_stage_2</th>\n",
       "      <th>reward</th>\n",
       "      <th>prev_reward</th>\n",
       "      <th>transation_prev</th>\n",
       "      <th>stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_statge_1  transation_type  action_stage_2  state_of_stage_2  reward  \\\n",
       "0              0.0                1             0.0               0.0     1.0   \n",
       "1              1.0                1             1.0               1.0     1.0   \n",
       "2              0.0                1             0.0               0.0     1.0   \n",
       "3              0.0                0             1.0               1.0     1.0   \n",
       "4              1.0                0             0.0               0.0     0.0   \n",
       "\n",
       "   prev_reward  transation_prev   stay  \n",
       "0          0.0                0  False  \n",
       "1          1.0                1  False  \n",
       "2          1.0                1  False  \n",
       "3          1.0                1   True  \n",
       "4          1.0                0  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The avarge rewared is = {}\".format(df['reward'].mean()))\n",
    "update_data_frame(df)\n",
    "stay_prob_df = calc_stay_probs(df)\n",
    "plot = plot_stay_probs(stay_prob_df['stay'].tolist())\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
